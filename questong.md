# lab2
- Що таке СЛАР;
  - Система лінійних алгебраічних рівнянь
- Яке завдання 2ї лабораторної роботи?
  - Для (симетричної за моїм варіантом) матриці вирішити СЛАР методом квадратичного кореня.
- Як дізнатись, що матриця симетрична:
   - Матриця - ця ж транспонована матриця повинно дорівнювати 0.
- Що таке факторизація
  - Розкладання. 
- Метод квадратного кореня - окремий випадок розкладання матриці на (LU) нижню та верхню трикутну для додатньо визначених матриць. 
- Додатньо визначена матриця - симетрична матриця для якої власні значення > 0;
- Власні значення це корені характеристичного рівняння, тобто значння  при яких A - eigenvals * np.eye() - I  
- Власні вектори - це вектори, при множенні яких на матрицю А - не міняють свій напрямок (лише довжину).
- Для яких матриць працює метод Холецького?
 - Симетричних та додатньо-визначених (власні значення > 0)
- Покзати у коді де кожен крок знаходження елементів матриць множників.
```python
if i == j: # діагональні елементи  
    sum = np.sum([u[k, i]**2 for k in range(i)]) 
    u[i, i] = np.sqrt(a[i, i] - sum) 
# діагональний елемент - квадратний корінь різниці між елементом матриці та сумою попередніх елементів того ж стовпця
else: # Верхня трикнутна матриця 
    sum = np.sum([u[k, i] * u[k, j] for k in range(i)])
    u[i, j] = (a[i, j] - sum) / u[i, i]
# Віднімаємо попередні елементи щоб виокремити i, j, прибираючи попередні елементи 
```
- Чому необхідний прямий та зворотній ходи?  
 - Зворотній хід потрібен аби розв'язати простіші системи Uy = b; Ux=y; Прямий - розкладає матрицю А.
- Показати у коді де знахдяться y та x; що які елементи задіюються.
```python
# T'y = b
y = np.zeros_like(b)
for i in range(n):
    sum = np.sum([u[k, i] * y[k] for k in range(i)]) 
    y[i] = (b[i] - sum) / u[i, i] 
# знаходимо кожен y віднімаючи суму добутку вже відомих множників ділячи на діагональний елемент (коофіцієнт y)
``` 
```python
x = np.zeros_like(b)
for i in range(n-1, -1, -1):
    sum = np.sum([u[i, k] * x[k] for k in range(i+1, n)])       
    x[i] = (y[i] - sum) / u[i, i]
# знаходимо кожен х віднімаючи суму добутку вже відомих множників ділячи на діагональний елемент (коофіцієнт х)
```
Це має сенс оскільки U та U.T це множники матриці А. 
- Що таке вектор нев'язки?
 - Різниця між правою частиною рівнянь (вектор б) та добутком матриці на отриманий розв'язок. ця різниця повина дорівнювати 0. 
- Система розв'язується у два етапи: спочатку U^T * y = b, потім U * x = y. Чому такий підхід ефективніший за пряме розв'язання системи? 
 - Розв'язок трикутних систем - послідовне перемноження скалярів. Пряме розв'язання потребувало б множення матриць, що має складність O(n^2). 

- Чому розклад Холецького існує тільки для симетричних додатно визначених матриць? 
  - Симетричність гарантує що елементи матриці зійдуться при множенні розкладених матриць (U, U.T). Всі діагональні елементи будуть додатніми ( не буде ділення на 0 ).
- Чому діагональні елементи u[i,i] обчислюються через квадратний корінь і які проблеми це може створювати?
  - При множенні розкладених матриць (U на U.T) діагональні елементи утворюються як суми квадратів елементів відповідного рядка. Тому небхідно брати корінт. (наприклад, a22 = l21² + l22²) 
- Як пов'язані визначник матриці A та добуток діагональних елементів матриці U?
  - Визначеник дорівнює добутку діагональних елементів матриці U.
- Чому у[i,j] = 0 для i < j (верхня трикутність) є оптимальним з точки зору обчислень?
   - Бо матриця симетрична, Нижня трикутна матриця є транспонованою верхньою 
- Чому розклад Холецького має вигляд A = U^T * U, а не просто A = U * U?
  - Множення U.T * U гарантує симетричність матриці. 
- Як пов'язані визначник матриці A і елементи матриці U?
  - Мтриця А додатньо визначена лише коли власні значення додатні, тобто є умовою для розкладу.
# lab3
- В чому полягає завдання лабораторної робти;
  - Вирішення СЛАР ітераційними методами якобі та зейделя.
  - Для мого варіанту необхідно було звести матрицю до такої, що має діагональну перевагу. 
  - Діагональна перевага визначається тим, що діагональний елемент більший за суму недіагональних елементів того ж рядку. 
  - Ітераційним методами є такі, що отримають розв'язок системи поступово лише із заданою точністю.

- Метод Якобі полягає у перетворенні вихідної системи лінійних рівнянь Ax=b до еквівалентного вигляду x=Bx+c шляхом одночасного обчислення наближень коренів за значеннями попередньої ітерації.
- Ітераційна матриця визначає як поточні корені впливають на наступні наближення. (B) Містить всі змінні частини системи.  
- Ітераційний вектор - (С) константна частина. 
- у чому полягає метод **зейделя?**
  - Модифікаці методу якобі де одразу використовуютьс нові значення для обчислення наступних наближенб.
```python
# Кожен наступний корень уточнюється попереднім? 
for i in range(n):
# сума вже обчислених компонент
 sum1 = sum(a[i,j] * x_new[j] for j in range(i))
# сума ще не обчислених
sum2 = sum(a[i,j] * x[j] for j in range(i+1, n))
# ділення виражає х з рівняння. (Bx+C)
x_new[i] = (b[i] - sum1 - sum2) / a[i,i]
```
- Що таке матриця С? 
  - Матриця С містить 1/aii, щоб одним множенням поділити всі рівняння на їх діагональні елементи і виразити кожне x.
- Чому необхідна діагональна перевага для методу простої ітерації (якобі)? 
    - діагональна перевага забезпечує збіжність процесу, тому що всі коофіцієнти B? будуть менші за одиницю, що не дозволяє рішеню розхитуватись
-  Який критерій закінчення ітераційного процесу;
    - Різниця між наближеннями менше заданої точності 
- Чому діагональне переважання гарантує збіжність?
    Коли ділимо рівняння на діагональний елемент (який найбільший), всі коефіцієнти ітераційної матриці B стають за модулем менше 1, через що кожна наступна ітерація дає менші зміни ніж попередні, тобто процес "затухає". У інакшому випадку процкес би розгойдувався. 
- Чому метод Зейделя збігається швидше за Якобі?
    - Метод якобі чекає ітерації щоб використати нові значення, коли метод зейделя робить це одразу. 
- Чому розбиття на L, D, U працює?
  - Це розклад матриці на верхню трикутну, діагональну та нижню трикутну матриці. 
- Чому використання нових значень прискорює збіжність?
    -   Нові значення точніші за попередні наближення; 
    -   За одну ітерацію якобі використовує лише старі наближення, у той час як зейделя і нові, і старі. 
- Який метод стійкіший до похибок округлення?
   - Метод якобі, значення х обчислюються незалежно один від одного. Тобто похибкба не накопичується в межах однієї ітерації. 
- Чому порядок обходу змінних важливий?
  - збіжність методу прискорюється послідовним обчисленням через матрицю коофіцієнтів (C). Інший порядок погіршить збіжність або унеможливить через накопичення похибки. 
- Що таке критерій збіжності?
  - Критерій що показує чи метод може збігтись, для якобі/зейделя - матриця повинна бути діагонально переважною.
- Як перевірити точність розв'язку?
  - Узявши різницю розв'зку помноженого на початкову матрицю з шуканим b (вектор нев'язки)
- Чому у методі Якобі використовується матричний підхід (iteration_matrix), а в методі Зейделя - поелементний?
    - Метод зейделя обраховує нові наближення послідовно, аби зменшити кількість ітерацій, тоді як у методі якобі наближення обраховуються незалежно кожноого циклу.
Як обчислюється матриця ітерацій у методі Якобі і чому вона має таку форму?
-  Як впливає перестановка рівнянь на збіжність методів?
   - Ніяк
# lab4


~
Що таке форма Фробеніуса (Frobenius)?
Це спеціальна канонічна форма матриці, яка зберігає її характеристичний многочлен. Матриця приводиться до вигляду:
Що таке власні значення (eigenvalues)?
Власні значення λ - це числа, для яких існує ненульовий вектор x такий, що Ax = λx, де A - вихідна матриця.
Чому y рахується як власні значення в степені?
В методі Фробеніуса компоненти власного вектора y обчислюються як степені власного значення λ: [λ³, λ², λ, 1]. Це випливає з структури матриці Фробеніуса.
Як перевірити правильність отриманого характеристичного полінома?

```
mat_m[idx-1] = [
    -mat_a_i[idx,j]/mat_a_i[idx,idx-1] 
    if j != m - i - 1 else 1 / mat_a_i[idx, idx-1]
    for j in range(m)]
```
Чому ми ділимо на елемент mat_a_i[idx,idx-1]?
Яка математична суть цього перетворення?


```
mat_y = np.array([
    [l**3, l**2, l, 1] for l in lambda_values
])
```

'''
Якщо у вас є матриця:
A = [
    [1, 2],
    [2, 1]
]
Як би ви знайшли її власні значення "вручну"?

'''

Як пов'язані діагональні елементи матриці Фробеніуса з коефіцієнтами характеристичного полінома?
Якщо матриця має кратні власні значення, як це вплине на процес знаходження власних векторів?
При обчисленні Y-матриці власних векторів, чому важливо використовувати саме таку степеневу послідовність?
Чому метод Данилевського може бути чисельно нестійким?
Який критерій можна використовувати для оцінки точності отриманих результатів?
Чому власні вектори, що відповідають різним власним значенням, лінійно незалежні?
Як нормалізація власних векторів впливає на результат?
```
# Чому такий порядок операцій?
mat_a_i = np.linalg.inv(mat_m) @ mat_a_i @ mat_m
Яка математична суть цього перетворення подібності?
Чому важливий порядок множення матриць?
```
Як пов'язані власні значення матриці з її діагоналізацією?
Які є альтернативні методи знаходження власних значень?
Де використовуються власні значення та вектори в реальних задачах?
Як власні значення пов'язані зі стійкістю динамічних систем?

Які властивості повинна мати результуюча матриця?


Чому степені йдуть від найвищої до 1?
Як це пов'язано з характеристичним поліномом?

Що потріьно було зробити у лабораторній та який мій варіант



Що таке матриця Ax, Mx, матриця суміжності
У чому полягає метод данилевського;
Що таке характеристичне рівняння
Що таке нормальна форма фронебіуса, як з неї знаходяться власні значення та чому це можливо 

Що таке власні значення та власні вектори

Що таке власні значення і власні вектори геометрично?
Чому форма Фробеніуса (супровідна матриця) зберігає власні значення?
Як пов'язані власні значення з характеристичним многочленом?
Чому метод Данилевського працює?

Що таке форма Фробеніуса і які її властивості?
Чому саме така структура матриці M_i?
Як довести, що перетворення подібності зберігає власні значення?
Як геометрично інтерпретувати перехід до форми Фробеніуса?
Чому послідовні перетворення подібності приводять до форми Фробеніуса?
Як обґрунтувати вибір елементів матриць M_i?
Як доводиться збіжність методу?
Які обмеження методу?

Чому коефіцієнти характеристичного полінома читаються з останнього рядка форми Фробеніуса?

Чому власні вектори мають вигляд степенів власних значень?

Що відбувається у випадку кратних власних значень?

Який зв'язок з канонічними формами?


# lab5

Про що лабраторна робота; 
У чому поглягає теорема ш турма; # метод поліномів штурма 
Теорема про верхню та нижні границі Гюа, 


метод бісекції у двох словах
метод хорд у двох словах
метод ньютона у двох словах
показати у коді розказати що робить кожен рядок 

який метод приводить до
меншої кількості ітерацій і чим це зумовлено.

Чому метод бісекції завжди збігається, але повільно?

к оцінити кількість ітерацій для досягнення заданої точності?

Чому важливо, щоб функція змінювала знак на кінцях відрізка?

Які недоліки методу при пошуку кратних коренів?

Чому швидкість збіжності методу хорд лінійна?

Як геометрично інтерпретується метод хорд?
хорд
Чому важливо правильно вибирати початкові наближення

ньютона 
Чому збіжність квадратична при простих коренях?
Як впливає кратність кореня на швидкість збіжності?
Чому метод може розбігатися і як цього уникнути?
Як вибір початкового наближення впливає на збіжність?



Як теорема про проміжне значення пов'язана з методом бісекції?
Як теорема про нерухому точку пов'язана з ітераційними методами?
Чому саме лінійна апроксимація використовується в методі хорд?
Як ряд Тейлора пов'язаний з методом Ньютона?
Як визначити, що метод розбігається?

Що робити, якщо функція не диференційована?

Як шукати комплексні корені?

Як пов'язані методи з оптимізаційними задачами?

Як боротися з накопиченням похибок?
Який зв'язок між методом Ньютона і градієнтним спуском?
Чому саме дотична використовується в методі Ньютона, а не інші апроксимації?

Чи існує універсальний метод з гарантованою збіжністю для довільної неперервної функції

Як теорема Галуа обмежує можливості аналітичного розв'язку?

Чи можливо створити метод з кубічною збіжністю без додаткових обчислень похідних?

Як методи працюють з алгебраїчними числами різних степенів?

Що таке послідовність Штурма?

Як формується послідовність Штурма?
к рахується кількість коренів на проміжку?
Чому працює підрахунок змін знаків?

Які обмеження методу?
У чому суть правила Гюа?
Як застосовується для відокремлення коренів?

Переваги і недоліки методу Штурма vs правила Гюа?
Складність обчислення послідовності Штурма


# lab7
що таке квадратура;
що таке поліноми лежандра ; 
Інтерполяційні поліноми у двох словах;
квадратура  трапецій у двох словах; 
з чого складаєься оцінка похибки формули трапецій 
що таке ортогональність  ( зокрема у поліномах лежандра )

ДЕ У КВАДРАТУРІ ГАУСА ЗАМІНА ЗМІННОЇ  
x = (b + a) / 2 z*(b-a)/2

з чого складається похибка квадратури гауса 
чому квадратура гауса ефективна до 2m-1 та до чого взагалі похідна в похибці 

що таке вагові коофіцієнти у квадратурі гауса 

Чому саме поліноми Лежандра використовуються в квадратурі Гауса, а не інші ортогональні поліноми? Які переваги це дає?

Чому квадратура Гауса точна для поліномів степеня до 2m-1, а не просто m?

Як співвідносяться локальна і глобальна похибки в методі трапецій?

Чому в оцінці похибки квадратури Гауса з'являється факторіал (2m)! і як це пов'язано з рядом Тейлора?

Як впливає погана обумовленість на точність обчислень при великих значеннях m?

Як вибрати оптимальне значення m для квадратури Гауса з урахуванням і точності, і обчислювальної складності?

У яких випадках метод трапецій може бути кращим вибором, ніж квадратура Гауса?

Як би змінилась ефективність методів при інтегруванні осцилюючих функцій?

Як можна адаптивно вибирати вузли інтегрування для покращення точності?

Чи можливо оцінити похибку без використання похідних високих порядків?

Як би змінився алгоритм для обчислення кратних інтегралів?

Яка асимптотична складність обчислення вузлів і вагових коефіцієнтів у квадратурі Гауса?

Як стабільність алгоритму залежить від вибору точок інтегрування?

Які існують методи прискорення збіжності для погано обумовлених інтегралів?

Як теорема про середнє значення інтеграла пов'язана з вибором вузлів у квадратурних формулах?

Чому саме ортогональні поліноми дають оптимальні точки для інтегрування?

Як пов'язані квадратурні формули з інтерполяцією Лагранжа?

Які переваги та недоліки методу Гауса порівняно з іншими методами чисельного інтегрування?
Які модифікації потрібні для стохастичних інтегралів?


# lab8

що таке проблема коші 

метод ейлера 
реверснутий метод ейлера 
показати звідки взялись коофіцієнти 
що це за коофіцієнти та чому k2 та k3 більш точні ніж k1 та k4 
чому похибка tau має сенс, з чого вона складається

чим відрізняється адаптивний rk4 від фіксованого 
Як вирігується розмір кроку, що таке правило рунге 

чому методу адамса потрібно три точки на початку
що таке метод адамса, що за формула інтерполяції та екстраполяції
що взагал таке інтерполяція та екстраполяція 

який order методу адамса та методу rk4 та чому .

як обраховується аналітична похибка методу адамса та чому саме так (чому рунге правило)

що таке фазовий портрет та що він показує 

Що означає A-стійкість та L-стійкість методу? Який з представлених методів має кращу стійкість для жорстких систем?
Який математичний сенс має tau_upper та tau_lower в адаптивному методі? Як правильно підбирати ці параметри?
Як впливає нелінійність диференційного рівняння на вибір оптимального кроку в адаптивному методі?
Як можна оцінити оптимальний порядок методу залежно від потрібної точності та властивостей диференційного рівняння?