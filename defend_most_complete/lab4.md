# Лабораторна робота: Зведення матриці до нормальної форми Фробеніуса та знаходження власних чисел

Задача лабораторної роботи полягала у тому, щоб звести матрицю до нормальної форми Фробеніуса, а потім знайти власні числа матриці А, тобто корені характеристичного рівняння.

## Функція для зведення матриці до нормальної форми Фробеніуса
> Основна ідея методу Фробеніуса полягає в перетворенні вихідної матриці до спеціальної канонічної форми через послідовність подібних перетворень. Процес відбувається ітеративно, обробляючи матрицю стовпець за стовпцем від останнього до першого. На кожній ітерації формується матриця перетворення та її обернена, які використовуються для занулення елементів під головною діагоналлю у відповідному стовпці. Ключовим кроком є множення поточної матриці зліва на обернену матрицю перетворення і справа на саму матрицю перетворення. Це наближення покращується з кожною ітерацією, оскільки кожне таке множення зануляє елементи в одному стовпці під головною діагоналлю, крім першого ненульового елемента, який стає одиницею. Таким чином, з кожним кроком матриця все більше наближається до форми Фробеніуса, де всі елементи під головною піддіагоналлю є одиницями, а решта елементів під головною діагоналлю - нулями. Цей процес зберігає характеристичний многочлен матриці, що робить отриману форму корисною для подальшого аналізу властивостей вихідної матриці, особливо для знаходження власних значень.

## Навіщо вона? 
>  нормальна форма Фробеніуса є ключовим елементом методу Данилевського для знаходження власних значень та векторів матриці. Вона дозволяє звести вихідну матрицю до спеціального вигляду, де характеристичний поліном можна безпосередньо зчитати з першого рядка матриці. Це суттєво спрощує процес обчислення власних значень, оскільки коефіцієнти характеристичного рівняння стають явно видимими. Форма Фробеніуса також забезпечує ефективний спосіб обчислення власних векторів, використовуючи степені власних значень. Таким чином, вона перетворює складну задачу знаходження власних значень та векторів на більш структуровану та обчислювально ефективну процедуру.


## Захист коду 


Спочатку ініціалізується вхідна матриця A:

```python
A = np.array([
    [7.03, 1.14, 0.93, 1.135],
    [1.14, 3.39, 1.3, 0.16],
    [0.93, 1.3, 6.21, 2.1],
    [1.135, 0.16, 2.1, 5.33]
])
```

Це симетрична матриця 4x4, яка є вхідними даними для нашого методу.

Перший етап методу починається з створення матриці M3:

```python
M3 = np.eye(4)
M3[2, :] = [-A[3,0]/A[3,2], -A[3,1]/A[3,2], 1/A[3,2], -A[3,3]/A[3,2]]
```

M3 є одиничною матрицею 4x4, де третій рядок (індекс 2) модифікується. Кожен елемент цього рядка обчислюється діленням відповідного елемента останнього рядка A на A[3,2], за винятком третього елемента, який є оберненим до A[3,2]. Це перетворення забезпечує занулення елементів під головною діагоналлю в останньому стовпці матриці A1:

```python
A1 = np.linalg.inv(M3) @ A @ M3
```

Тут ми множимо A зліва на обернену M3 і справа на M3. Це еквівалентно перетворенню подібності, яке зберігає власні значення матриці.

Другий етап аналогічний першому, але тепер створюється матриця M2:

```python
M2 = np.eye(4)
M2[1, :] = [-A1[2,0]/A1[2,1], 1/A1[2,1], -A1[2,2]/A1[2,1], -A1[2,3]/A1[2,1]]
A2 = np.linalg.inv(M2) @ A1 @ M2
```

M2 модифікує другий рядок (індекс 1) A1. Це призводить до занулення елементів під головною діагоналлю в передостанньому стовпці матриці A2.

На третьому етапі створюється матриця M1:

```python
M1 = np.eye(4)
M1[0, :] = [1/A2[1,0], -A2[1,1]/A2[1,0], -A2[1,2]/A2[1,0], -A2[1,3]/A2[1,0]]
P = np.linalg.inv(M1) @ A2 @ M1
```

M1 модифікує перший рядок (індекс 0) A2. Результатом є матриця P у формі Фробеніуса, де всі елементи під головною діагоналлю, крім тих, що безпосередньо під нею, дорівнюють нулю.

Далі формується вектор V з коефіцієнтів характеристичного полінома матриці P:

```python
V = np.array([-P[0,3], -P[0,2], -P[0,1], -P[0,0], 1])
lambda_values = np.roots(V[::-1])
```

V містить коефіцієнти характеристичного полінома в порядку зростання степенів, а np.roots знаходить його корені, які є власними значеннями вихідної матриці A.

Для знаходження власних векторів створюється матриця Y:

```python
Y = np.array([
    [l**3, l**2, l, 1] for l in lambda_values
])
```

Кожен рядок Y є степенями відповідного власного значення, що відповідає власному вектору в базисі матриці P.

Матриця подібності S використовується для перетворення цих векторів назад до базису вихідної матриці A:

```python
S = M3 @ M2 @ M1
eigenvectors = S @ Y.T
```

S є добутком всіх матриць перетворення, а eigenvectors містить власні вектори A.

Нарешті, проводиться перевірка точності обчислень:

```python
for i, (lambda_i, v) in enumerate(zip(lambda_values, eigenvectors.T), 1):
    error = np.linalg.norm(A @ v - lambda_i * v)
    print(f"Помилка для λ_{i}: {error:.2e}")
```

Ця перевірка обчислює норму різниці між A*v та λ*v для кожного власного значення і вектора, що дає оцінку точності обчислень.

Метод Данилевського ефективно знаходить власні значення та вектори матриці, особливо для матриць високого порядку, уникаючи прямого розв'язання характеристичного рівняння.

Матриця називається невиродженою (або оборотною), якщо її визначник не дорівнює нулю.


## Обмеження у застосуванні 

Чутливість до помилок округлення при роботі з великими матрицями.

Нестабільність для вироджених або близьких до вироджених матриць.

Зниження ефективності для матриць дуже великого розміру.

Складніша реалізація порівняно з деякими іншими методами.

Можливі труднощі з точним обчисленням комплексних власних значень.

Залежність ефективності від вибору опорних елементів.

## Головний елемент
Головний елемент у контексті чисельних методів, зокрема в методі Гауса з вибором головного елемента, - це елемент матриці, який вибирається як опорний для подальших обчислень. Зазвичай це найбільший за абсолютною величиною елемент у певному стовпці або підматриці.